{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io_tools as iot\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import sys\n",
    "import copy\n",
    "import pdb\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "\n",
    "from transformers import *\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "\n",
    "DATA_DIR = '/media/raid_arr/data/otto/data/'\n",
    "DB_OUT_TRAIN = os.path.join(DATA_DIR, 'train_lvl')\n",
    "DB_OUT_TEST = os.path.join(DATA_DIR, 'test_lvl')\n",
    "DB_OUT_ALL = os.path.join(DATA_DIR, 'all_lvl')\n",
    "DB_OUT_ALL0 = os.path.join(DATA_DIR, 'all0_lvl')\n",
    "\n",
    "def _load_data():\n",
    "#     data = pickle.load(open(os.path.join(DATA_DIR, 'transformed_data.p'), 'rb'))\n",
    "#     data = pickle.load(gzip.open(os.path.join(DATA_DIR, 'log_data.pgz'), 'rb'))\n",
    "    data = pickle.load(gzip.open(os.path.join(DATA_DIR, 'iden-log-anscombe_data.pgz'), 'rb'))\n",
    "    #data = pickle.load(gzip.open(os.path.join(DATA_DIR, 'iden-log-anscombe-inv_data.pgz'), 'rb'))\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ids_train, feats_train, labels_train\n",
    "except NameError:\n",
    "    ids_train = np.load(os.path.join(iot.DATA_DIR, 'train_ids.npy'))\n",
    "    feats_train = np.load(os.path.join(iot.DATA_DIR, 'train_feats.npy')).astype(float)\n",
    "    labels_train = np.load(os.path.join(iot.DATA_DIR, 'train_labels_enc.npy'))\n",
    "\n",
    "try:\n",
    "    ids_test, feats_test\n",
    "except NameError:\n",
    "    ids_test = np.load(os.path.join(iot.DATA_DIR, 'test_ids.npy'))\n",
    "    feats_test = np.load(os.path.join(iot.DATA_DIR, 'test_feats.npy')).astype(float)   \n",
    "    \n",
    "skf = StratifiedKFold(labels_train, n_folds=5, shuffle=True)\n",
    "# All\n",
    "feats_all = np.r_[feats_train, feats_test]\n",
    "labels_all = np.r_[labels_train, -1*np.ones(len(ids_test))].astype(int)\n",
    "\n",
    "# All minus test0\n",
    "train_ind, val_ind = iter(skf).next()\n",
    "feats_all0 = np.r_[feats_train[train_ind, :], feats_test]\n",
    "labels_all0 = np.r_[labels_train[train_ind], -1*np.ones(len(ids_test))].astype(int)\n",
    "\n",
    "\n",
    "feats_fold_train = feats_train[train_ind, :]\n",
    "labels_fold_train = labels_train[train_ind]\n",
    "feats_fold_val = feats_train[val_ind, :]\n",
    "labels_fold_val = labels_train[val_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipe = make_pipeline(IdentityTformer())\n",
    "pipe = make_pipeline(AnscombeTformer())\n",
    "pipe.fit(np.r_[feats_train[train_ind, :], feats_test])\n",
    "\n",
    "X_train = pipe.transform(feats_fold_train)\n",
    "y_train = labels_fold_train\n",
    "\n",
    "X_valid = pipe.transform(feats_fold_val)\n",
    "y_valid = labels_fold_val\n",
    "\n",
    "X_test = pipe.transform(feats_test)\n",
    "y_test = -1*np.ones(len(feats_test), dtype=int)\n",
    "\n",
    "data = ((X_train, y_train),\n",
    "        (X_valid, y_valid),\n",
    "        (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data = _load_data()\n",
    "X_train, y_train = data[0]\n",
    "X_valid, y_valid = data[1]\n",
    "X_test, y_test = data[2]\n",
    "\n",
    "# Prep data for xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# # Save binary for faser loading next time?\n",
    "# dtrain.save_binary(os.path.join(DATA_DIR, 'train.buffer'))\n",
    "# dvalid.save_binary(os.path.join(DATA_DIR, 'valid.buffer'))\n",
    "# dtest.save_binary(os.path.join(DATA_DIR, 'test.buffer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters for XGB\n",
    "params = {\n",
    "    'num_class': len(np.unique(y_train)),\n",
    "    'silent': 0,    # 0 is verbose\n",
    "    'nthread': 7,    # max if not set\n",
    "    \n",
    "    'bst:eta': 0.2,\n",
    "    'bst:gamma': 1,\n",
    "    'bst:max_depth': 10,\n",
    "    'bst:min_child_weight': 3,\n",
    "    'bst:max_delta_step': 0,\n",
    "    'bst:subsample': 0.9,    # Row (observation) subsample\n",
    "    'bst:colsample_bytree': 0.6,    # Col (feature) subsample\n",
    "    \n",
    "    'objective':'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    \n",
    "    'seed': 0,\n",
    "}\n",
    "plst = params.items()\n",
    "evallist  = [(dtrain,'train'), (dvalid,'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until valid error hasn't decreased in 20 rounds.\n",
      "[0]\ttrain-mlogloss:1.721208\tvalid-mlogloss:1.734424\n",
      "[1]\ttrain-mlogloss:1.469426\tvalid-mlogloss:1.495596\n",
      "[2]\ttrain-mlogloss:1.290452\tvalid-mlogloss:1.328939\n",
      "[3]\ttrain-mlogloss:1.151028\tvalid-mlogloss:1.197976\n",
      "[4]\ttrain-mlogloss:1.039470\tvalid-mlogloss:1.093960\n",
      "[5]\ttrain-mlogloss:0.950985\tvalid-mlogloss:1.012745\n",
      "[6]\ttrain-mlogloss:0.873907\tvalid-mlogloss:0.942333\n",
      "[7]\ttrain-mlogloss:0.808520\tvalid-mlogloss:0.883082\n",
      "[8]\ttrain-mlogloss:0.757303\tvalid-mlogloss:0.837048\n",
      "[9]\ttrain-mlogloss:0.710887\tvalid-mlogloss:0.794784\n",
      "[10]\ttrain-mlogloss:0.670939\tvalid-mlogloss:0.759446\n",
      "[11]\ttrain-mlogloss:0.634583\tvalid-mlogloss:0.729187\n",
      "[12]\ttrain-mlogloss:0.606064\tvalid-mlogloss:0.705582\n",
      "[13]\ttrain-mlogloss:0.577943\tvalid-mlogloss:0.681897\n",
      "[14]\ttrain-mlogloss:0.555185\tvalid-mlogloss:0.663917\n",
      "[15]\ttrain-mlogloss:0.533940\tvalid-mlogloss:0.646268\n",
      "[16]\ttrain-mlogloss:0.515518\tvalid-mlogloss:0.631242\n",
      "[17]\ttrain-mlogloss:0.499207\tvalid-mlogloss:0.618307\n",
      "[18]\ttrain-mlogloss:0.483804\tvalid-mlogloss:0.606165\n",
      "[19]\ttrain-mlogloss:0.470124\tvalid-mlogloss:0.596228\n",
      "[20]\ttrain-mlogloss:0.458091\tvalid-mlogloss:0.586342\n",
      "[21]\ttrain-mlogloss:0.448018\tvalid-mlogloss:0.577999\n",
      "[22]\ttrain-mlogloss:0.436916\tvalid-mlogloss:0.569914\n",
      "[23]\ttrain-mlogloss:0.427692\tvalid-mlogloss:0.563035\n",
      "[24]\ttrain-mlogloss:0.418099\tvalid-mlogloss:0.556193\n",
      "[25]\ttrain-mlogloss:0.410350\tvalid-mlogloss:0.550581\n",
      "[26]\ttrain-mlogloss:0.403894\tvalid-mlogloss:0.545930\n",
      "[27]\ttrain-mlogloss:0.396724\tvalid-mlogloss:0.540971\n",
      "[28]\ttrain-mlogloss:0.389589\tvalid-mlogloss:0.536512\n",
      "[29]\ttrain-mlogloss:0.384519\tvalid-mlogloss:0.532661\n",
      "[30]\ttrain-mlogloss:0.378722\tvalid-mlogloss:0.529019\n",
      "[31]\ttrain-mlogloss:0.374430\tvalid-mlogloss:0.525808\n",
      "[32]\ttrain-mlogloss:0.370458\tvalid-mlogloss:0.523220\n",
      "[33]\ttrain-mlogloss:0.366580\tvalid-mlogloss:0.520361\n",
      "[34]\ttrain-mlogloss:0.362537\tvalid-mlogloss:0.517934\n",
      "[35]\ttrain-mlogloss:0.358731\tvalid-mlogloss:0.515472\n",
      "[36]\ttrain-mlogloss:0.355796\tvalid-mlogloss:0.513241\n",
      "[37]\ttrain-mlogloss:0.351429\tvalid-mlogloss:0.511035\n",
      "[38]\ttrain-mlogloss:0.347626\tvalid-mlogloss:0.508925\n",
      "[39]\ttrain-mlogloss:0.344133\tvalid-mlogloss:0.506943\n",
      "[40]\ttrain-mlogloss:0.339923\tvalid-mlogloss:0.504709\n",
      "[41]\ttrain-mlogloss:0.337482\tvalid-mlogloss:0.503161\n",
      "[42]\ttrain-mlogloss:0.333880\tvalid-mlogloss:0.501249\n",
      "[43]\ttrain-mlogloss:0.331091\tvalid-mlogloss:0.499454\n",
      "[44]\ttrain-mlogloss:0.328707\tvalid-mlogloss:0.497962\n",
      "[45]\ttrain-mlogloss:0.325915\tvalid-mlogloss:0.496598\n",
      "[46]\ttrain-mlogloss:0.323089\tvalid-mlogloss:0.495146\n",
      "[47]\ttrain-mlogloss:0.320413\tvalid-mlogloss:0.493767\n",
      "[48]\ttrain-mlogloss:0.317721\tvalid-mlogloss:0.492362\n",
      "[49]\ttrain-mlogloss:0.315843\tvalid-mlogloss:0.491173\n",
      "[50]\ttrain-mlogloss:0.313341\tvalid-mlogloss:0.490289\n",
      "[51]\ttrain-mlogloss:0.310416\tvalid-mlogloss:0.488851\n",
      "[52]\ttrain-mlogloss:0.307946\tvalid-mlogloss:0.488028\n",
      "[53]\ttrain-mlogloss:0.305763\tvalid-mlogloss:0.486729\n",
      "[54]\ttrain-mlogloss:0.303422\tvalid-mlogloss:0.485554\n",
      "[55]\ttrain-mlogloss:0.301417\tvalid-mlogloss:0.484554\n",
      "[56]\ttrain-mlogloss:0.299483\tvalid-mlogloss:0.483624\n",
      "[57]\ttrain-mlogloss:0.297146\tvalid-mlogloss:0.482606\n",
      "[58]\ttrain-mlogloss:0.294768\tvalid-mlogloss:0.481836\n",
      "[59]\ttrain-mlogloss:0.293028\tvalid-mlogloss:0.480981\n",
      "[60]\ttrain-mlogloss:0.290820\tvalid-mlogloss:0.480332\n",
      "[61]\ttrain-mlogloss:0.289072\tvalid-mlogloss:0.479541\n",
      "[62]\ttrain-mlogloss:0.287553\tvalid-mlogloss:0.478979\n",
      "[63]\ttrain-mlogloss:0.285750\tvalid-mlogloss:0.478373\n",
      "[64]\ttrain-mlogloss:0.283693\tvalid-mlogloss:0.477631\n",
      "[65]\ttrain-mlogloss:0.281311\tvalid-mlogloss:0.476628\n",
      "[66]\ttrain-mlogloss:0.279739\tvalid-mlogloss:0.476024\n",
      "[67]\ttrain-mlogloss:0.278015\tvalid-mlogloss:0.475702\n",
      "[68]\ttrain-mlogloss:0.276736\tvalid-mlogloss:0.475073\n",
      "[69]\ttrain-mlogloss:0.275174\tvalid-mlogloss:0.474541\n",
      "[70]\ttrain-mlogloss:0.273257\tvalid-mlogloss:0.473744\n",
      "[71]\ttrain-mlogloss:0.271691\tvalid-mlogloss:0.473191\n",
      "[72]\ttrain-mlogloss:0.270935\tvalid-mlogloss:0.472900\n",
      "[73]\ttrain-mlogloss:0.270174\tvalid-mlogloss:0.472603\n",
      "[74]\ttrain-mlogloss:0.268914\tvalid-mlogloss:0.472144\n",
      "[75]\ttrain-mlogloss:0.267651\tvalid-mlogloss:0.471581\n",
      "[76]\ttrain-mlogloss:0.266165\tvalid-mlogloss:0.471291\n",
      "[77]\ttrain-mlogloss:0.264835\tvalid-mlogloss:0.470724\n",
      "[78]\ttrain-mlogloss:0.263995\tvalid-mlogloss:0.470700\n",
      "[79]\ttrain-mlogloss:0.262635\tvalid-mlogloss:0.470351\n",
      "[80]\ttrain-mlogloss:0.261526\tvalid-mlogloss:0.470027\n",
      "[81]\ttrain-mlogloss:0.260579\tvalid-mlogloss:0.469654\n",
      "[82]\ttrain-mlogloss:0.259286\tvalid-mlogloss:0.469330\n",
      "[83]\ttrain-mlogloss:0.257675\tvalid-mlogloss:0.468695\n",
      "[84]\ttrain-mlogloss:0.256839\tvalid-mlogloss:0.468246\n",
      "[85]\ttrain-mlogloss:0.255818\tvalid-mlogloss:0.468130\n",
      "[86]\ttrain-mlogloss:0.254827\tvalid-mlogloss:0.467963\n",
      "[87]\ttrain-mlogloss:0.253481\tvalid-mlogloss:0.467532\n",
      "[88]\ttrain-mlogloss:0.251917\tvalid-mlogloss:0.467228\n",
      "[89]\ttrain-mlogloss:0.250751\tvalid-mlogloss:0.467001\n",
      "[90]\ttrain-mlogloss:0.250004\tvalid-mlogloss:0.466670\n",
      "[91]\ttrain-mlogloss:0.248925\tvalid-mlogloss:0.466490\n",
      "[92]\ttrain-mlogloss:0.247511\tvalid-mlogloss:0.466131\n",
      "[93]\ttrain-mlogloss:0.246549\tvalid-mlogloss:0.465810\n",
      "[94]\ttrain-mlogloss:0.245305\tvalid-mlogloss:0.465651\n",
      "[95]\ttrain-mlogloss:0.244313\tvalid-mlogloss:0.465582\n",
      "[96]\ttrain-mlogloss:0.243086\tvalid-mlogloss:0.465210\n",
      "[97]\ttrain-mlogloss:0.242286\tvalid-mlogloss:0.464951\n",
      "[98]\ttrain-mlogloss:0.241546\tvalid-mlogloss:0.464751\n",
      "[99]\ttrain-mlogloss:0.240789\tvalid-mlogloss:0.464736\n",
      "[100]\ttrain-mlogloss:0.239936\tvalid-mlogloss:0.464479\n",
      "[101]\ttrain-mlogloss:0.239115\tvalid-mlogloss:0.464338\n",
      "[102]\ttrain-mlogloss:0.238515\tvalid-mlogloss:0.464292\n",
      "[103]\ttrain-mlogloss:0.237624\tvalid-mlogloss:0.464165\n",
      "[104]\ttrain-mlogloss:0.236212\tvalid-mlogloss:0.463709\n",
      "[105]\ttrain-mlogloss:0.235203\tvalid-mlogloss:0.463418\n",
      "[106]\ttrain-mlogloss:0.234115\tvalid-mlogloss:0.463328\n",
      "[107]\ttrain-mlogloss:0.233048\tvalid-mlogloss:0.463097\n",
      "[108]\ttrain-mlogloss:0.232213\tvalid-mlogloss:0.462775\n",
      "[109]\ttrain-mlogloss:0.231547\tvalid-mlogloss:0.462576\n",
      "[110]\ttrain-mlogloss:0.230676\tvalid-mlogloss:0.462302\n",
      "[111]\ttrain-mlogloss:0.230313\tvalid-mlogloss:0.462152\n",
      "[112]\ttrain-mlogloss:0.229510\tvalid-mlogloss:0.461816\n",
      "[113]\ttrain-mlogloss:0.228610\tvalid-mlogloss:0.461431\n",
      "[114]\ttrain-mlogloss:0.227722\tvalid-mlogloss:0.461290\n",
      "[115]\ttrain-mlogloss:0.227100\tvalid-mlogloss:0.461020\n",
      "[116]\ttrain-mlogloss:0.226693\tvalid-mlogloss:0.460977\n",
      "[117]\ttrain-mlogloss:0.225987\tvalid-mlogloss:0.460677\n",
      "[118]\ttrain-mlogloss:0.225351\tvalid-mlogloss:0.460577\n",
      "[119]\ttrain-mlogloss:0.224523\tvalid-mlogloss:0.460387\n",
      "[120]\ttrain-mlogloss:0.223447\tvalid-mlogloss:0.460325\n",
      "[121]\ttrain-mlogloss:0.222516\tvalid-mlogloss:0.460182\n",
      "[122]\ttrain-mlogloss:0.221864\tvalid-mlogloss:0.459990\n",
      "[123]\ttrain-mlogloss:0.220900\tvalid-mlogloss:0.459927\n",
      "[124]\ttrain-mlogloss:0.220409\tvalid-mlogloss:0.459634\n",
      "[125]\ttrain-mlogloss:0.219935\tvalid-mlogloss:0.459428\n",
      "[126]\ttrain-mlogloss:0.219314\tvalid-mlogloss:0.459541\n",
      "[127]\ttrain-mlogloss:0.218673\tvalid-mlogloss:0.459383\n",
      "[128]\ttrain-mlogloss:0.218203\tvalid-mlogloss:0.459215\n",
      "[129]\ttrain-mlogloss:0.217542\tvalid-mlogloss:0.458921\n",
      "[130]\ttrain-mlogloss:0.216707\tvalid-mlogloss:0.458860\n",
      "[131]\ttrain-mlogloss:0.216182\tvalid-mlogloss:0.458980\n",
      "[132]\ttrain-mlogloss:0.215395\tvalid-mlogloss:0.458749\n",
      "[133]\ttrain-mlogloss:0.214935\tvalid-mlogloss:0.458633\n",
      "[134]\ttrain-mlogloss:0.214213\tvalid-mlogloss:0.458404\n",
      "[135]\ttrain-mlogloss:0.213811\tvalid-mlogloss:0.458360\n",
      "[136]\ttrain-mlogloss:0.213522\tvalid-mlogloss:0.458272\n",
      "[137]\ttrain-mlogloss:0.213097\tvalid-mlogloss:0.458157\n",
      "[138]\ttrain-mlogloss:0.212648\tvalid-mlogloss:0.458032\n",
      "[139]\ttrain-mlogloss:0.212007\tvalid-mlogloss:0.457975\n",
      "[140]\ttrain-mlogloss:0.211461\tvalid-mlogloss:0.457931\n",
      "[141]\ttrain-mlogloss:0.210688\tvalid-mlogloss:0.457764\n",
      "[142]\ttrain-mlogloss:0.209931\tvalid-mlogloss:0.457559\n",
      "[143]\ttrain-mlogloss:0.209410\tvalid-mlogloss:0.457471\n",
      "[144]\ttrain-mlogloss:0.208818\tvalid-mlogloss:0.457257\n",
      "[145]\ttrain-mlogloss:0.208382\tvalid-mlogloss:0.457220\n",
      "[146]\ttrain-mlogloss:0.207453\tvalid-mlogloss:0.457294\n",
      "[147]\ttrain-mlogloss:0.206577\tvalid-mlogloss:0.457113\n",
      "[148]\ttrain-mlogloss:0.206223\tvalid-mlogloss:0.457025\n",
      "[149]\ttrain-mlogloss:0.205472\tvalid-mlogloss:0.457001\n",
      "[150]\ttrain-mlogloss:0.204827\tvalid-mlogloss:0.456794\n",
      "[151]\ttrain-mlogloss:0.204266\tvalid-mlogloss:0.456735\n",
      "[152]\ttrain-mlogloss:0.203738\tvalid-mlogloss:0.456796\n",
      "[153]\ttrain-mlogloss:0.202874\tvalid-mlogloss:0.456839\n",
      "[154]\ttrain-mlogloss:0.202514\tvalid-mlogloss:0.456939\n",
      "[155]\ttrain-mlogloss:0.202114\tvalid-mlogloss:0.456922\n",
      "[156]\ttrain-mlogloss:0.201903\tvalid-mlogloss:0.456902\n",
      "[157]\ttrain-mlogloss:0.201134\tvalid-mlogloss:0.456994\n",
      "[158]\ttrain-mlogloss:0.200620\tvalid-mlogloss:0.456790\n",
      "[159]\ttrain-mlogloss:0.200137\tvalid-mlogloss:0.456701\n",
      "[160]\ttrain-mlogloss:0.199386\tvalid-mlogloss:0.456690\n",
      "[161]\ttrain-mlogloss:0.198925\tvalid-mlogloss:0.456647\n",
      "[162]\ttrain-mlogloss:0.198264\tvalid-mlogloss:0.456566\n",
      "[163]\ttrain-mlogloss:0.197907\tvalid-mlogloss:0.456776\n",
      "[164]\ttrain-mlogloss:0.197377\tvalid-mlogloss:0.456728\n",
      "[165]\ttrain-mlogloss:0.197143\tvalid-mlogloss:0.456698\n",
      "[166]\ttrain-mlogloss:0.196706\tvalid-mlogloss:0.456536\n",
      "[167]\ttrain-mlogloss:0.196263\tvalid-mlogloss:0.456496\n",
      "[168]\ttrain-mlogloss:0.195878\tvalid-mlogloss:0.456342\n",
      "[169]\ttrain-mlogloss:0.195451\tvalid-mlogloss:0.456432\n",
      "[170]\ttrain-mlogloss:0.194917\tvalid-mlogloss:0.456513\n",
      "[171]\ttrain-mlogloss:0.194415\tvalid-mlogloss:0.456541\n",
      "[172]\ttrain-mlogloss:0.194091\tvalid-mlogloss:0.456454\n",
      "[173]\ttrain-mlogloss:0.193559\tvalid-mlogloss:0.456234\n",
      "[174]\ttrain-mlogloss:0.193093\tvalid-mlogloss:0.456182\n",
      "[175]\ttrain-mlogloss:0.192789\tvalid-mlogloss:0.456052\n",
      "[176]\ttrain-mlogloss:0.192534\tvalid-mlogloss:0.455971\n",
      "[177]\ttrain-mlogloss:0.192013\tvalid-mlogloss:0.455910\n",
      "[178]\ttrain-mlogloss:0.191409\tvalid-mlogloss:0.455744\n",
      "[179]\ttrain-mlogloss:0.191239\tvalid-mlogloss:0.455797\n",
      "[180]\ttrain-mlogloss:0.190917\tvalid-mlogloss:0.455897\n",
      "[181]\ttrain-mlogloss:0.190433\tvalid-mlogloss:0.456020\n",
      "[182]\ttrain-mlogloss:0.189884\tvalid-mlogloss:0.455938\n",
      "[183]\ttrain-mlogloss:0.189602\tvalid-mlogloss:0.455910\n",
      "[184]\ttrain-mlogloss:0.189298\tvalid-mlogloss:0.455972\n",
      "[185]\ttrain-mlogloss:0.188911\tvalid-mlogloss:0.455829\n",
      "[186]\ttrain-mlogloss:0.188415\tvalid-mlogloss:0.455609\n",
      "[187]\ttrain-mlogloss:0.188048\tvalid-mlogloss:0.455560\n",
      "[188]\ttrain-mlogloss:0.187745\tvalid-mlogloss:0.455575\n",
      "[189]\ttrain-mlogloss:0.187368\tvalid-mlogloss:0.455485\n",
      "[190]\ttrain-mlogloss:0.186965\tvalid-mlogloss:0.455405\n",
      "[191]\ttrain-mlogloss:0.186862\tvalid-mlogloss:0.455474\n",
      "[192]\ttrain-mlogloss:0.186632\tvalid-mlogloss:0.455477\n",
      "[193]\ttrain-mlogloss:0.186283\tvalid-mlogloss:0.455468\n",
      "[194]\ttrain-mlogloss:0.185821\tvalid-mlogloss:0.455561\n",
      "[195]\ttrain-mlogloss:0.185630\tvalid-mlogloss:0.455435\n",
      "[196]\ttrain-mlogloss:0.185312\tvalid-mlogloss:0.455503\n",
      "[197]\ttrain-mlogloss:0.184930\tvalid-mlogloss:0.455439\n",
      "[198]\ttrain-mlogloss:0.184527\tvalid-mlogloss:0.455311\n",
      "[199]\ttrain-mlogloss:0.184294\tvalid-mlogloss:0.455344\n",
      "[200]\ttrain-mlogloss:0.183973\tvalid-mlogloss:0.455299\n",
      "[201]\ttrain-mlogloss:0.183736\tvalid-mlogloss:0.455291\n",
      "[202]\ttrain-mlogloss:0.183539\tvalid-mlogloss:0.455172\n",
      "[203]\ttrain-mlogloss:0.183246\tvalid-mlogloss:0.455275\n",
      "[204]\ttrain-mlogloss:0.182861\tvalid-mlogloss:0.455227\n",
      "[205]\ttrain-mlogloss:0.182663\tvalid-mlogloss:0.455268\n",
      "[206]\ttrain-mlogloss:0.182268\tvalid-mlogloss:0.455214\n",
      "[207]\ttrain-mlogloss:0.182021\tvalid-mlogloss:0.455248\n",
      "[208]\ttrain-mlogloss:0.181843\tvalid-mlogloss:0.455073\n",
      "[209]\ttrain-mlogloss:0.181584\tvalid-mlogloss:0.455005\n",
      "[210]\ttrain-mlogloss:0.181385\tvalid-mlogloss:0.454966\n",
      "[211]\ttrain-mlogloss:0.181092\tvalid-mlogloss:0.454947\n",
      "[212]\ttrain-mlogloss:0.180645\tvalid-mlogloss:0.454998\n",
      "[213]\ttrain-mlogloss:0.180330\tvalid-mlogloss:0.455011\n",
      "[214]\ttrain-mlogloss:0.179945\tvalid-mlogloss:0.455097\n",
      "[215]\ttrain-mlogloss:0.179842\tvalid-mlogloss:0.455132\n",
      "[216]\ttrain-mlogloss:0.179256\tvalid-mlogloss:0.455283\n",
      "[217]\ttrain-mlogloss:0.179110\tvalid-mlogloss:0.455264\n",
      "[218]\ttrain-mlogloss:0.178741\tvalid-mlogloss:0.455213\n",
      "[219]\ttrain-mlogloss:0.178372\tvalid-mlogloss:0.455444\n",
      "[220]\ttrain-mlogloss:0.178129\tvalid-mlogloss:0.455429\n",
      "[221]\ttrain-mlogloss:0.177850\tvalid-mlogloss:0.455398\n",
      "[222]\ttrain-mlogloss:0.177621\tvalid-mlogloss:0.455373\n",
      "[223]\ttrain-mlogloss:0.177476\tvalid-mlogloss:0.455279\n",
      "[224]\ttrain-mlogloss:0.177202\tvalid-mlogloss:0.455351\n",
      "[225]\ttrain-mlogloss:0.177044\tvalid-mlogloss:0.455359\n",
      "[226]\ttrain-mlogloss:0.176831\tvalid-mlogloss:0.455371\n",
      "[227]\ttrain-mlogloss:0.176696\tvalid-mlogloss:0.455428\n",
      "[228]\ttrain-mlogloss:0.176420\tvalid-mlogloss:0.455338\n",
      "[229]\ttrain-mlogloss:0.176020\tvalid-mlogloss:0.455263\n",
      "[230]\ttrain-mlogloss:0.175924\tvalid-mlogloss:0.455295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 177.322 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[231]\ttrain-mlogloss:0.175663\tvalid-mlogloss:0.455343\n",
      "Stopping. Best iteration:\n",
      "[211]\ttrain-mlogloss:0.181092\tvalid-mlogloss:0.454947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "num_round = 500\n",
    "bst = xgb.train(plst, dtrain, num_round, evallist,\n",
    "               early_stopping_rounds=20)\n",
    "toc = time() - tic\n",
    "print 'Train time: %g s' % toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  1.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       ..., \n",
       "       [  4.,   0.,   0., ...,   0.,   1.,   0.],\n",
       "       [  1.,   0.,   0., ...,   3.,  10.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   2.,   0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
